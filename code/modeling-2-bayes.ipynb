{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling - Naive Bayes (after deep data cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import plot_confusion_matrix, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data\n",
    "\n",
    "postings = pd.read_csv('../datasets/postings_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hiking</td>\n",
       "      <td>boulder flatiron loop hike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hiking</td>\n",
       "      <td>washington state lakes to swim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hiking</td>\n",
       "      <td>here a fun episode demonstrating why a is a fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hiking</td>\n",
       "      <td>picture i took of my friend at angel s landing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hiking</td>\n",
       "      <td>hiking to bertha peak via cougar crest trail a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11852</th>\n",
       "      <td>gardening</td>\n",
       "      <td>nope haha oklahoma so not too far away</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11853</th>\n",
       "      <td>gardening</td>\n",
       "      <td>i transitioning to everbearing in strawberry p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11854</th>\n",
       "      <td>gardening</td>\n",
       "      <td>so pretty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11855</th>\n",
       "      <td>gardening</td>\n",
       "      <td>i think it s chance of frost after that date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11856</th>\n",
       "      <td>gardening</td>\n",
       "      <td>my understanding is that the caterpillars eat ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11857 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           topic                                               text\n",
       "0         hiking                         boulder flatiron loop hike\n",
       "1         hiking                     washington state lakes to swim\n",
       "2         hiking  here a fun episode demonstrating why a is a fo...\n",
       "3         hiking  picture i took of my friend at angel s landing...\n",
       "4         hiking  hiking to bertha peak via cougar crest trail a...\n",
       "...          ...                                                ...\n",
       "11852  gardening             nope haha oklahoma so not too far away\n",
       "11853  gardening  i transitioning to everbearing in strawberry p...\n",
       "11854  gardening                                          so pretty\n",
       "11855  gardening       i think it s chance of frost after that date\n",
       "11856  gardening  my understanding is that the caterpillars eat ...\n",
       "\n",
       "[11857 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define X and y\n",
    "\n",
    "X = postings['text']\n",
    "y = np.where(postings['topic'] == 'hiking',1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                               boulder flatiron loop hike\n",
       "1                           washington state lakes to swim\n",
       "2        here a fun episode demonstrating why a is a fo...\n",
       "3        picture i took of my friend at angel s landing...\n",
       "4        hiking to bertha peak via cougar crest trail a...\n",
       "                               ...                        \n",
       "11852               nope haha oklahoma so not too far away\n",
       "11853    i transitioning to everbearing in strawberry p...\n",
       "11854                                            so pretty\n",
       "11855         i think it s chance of frost after that date\n",
       "11856    my understanding is that the caterpillars eat ...\n",
       "Name: text, Length: 11857, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking X\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking y\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, test, split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, stratify=y, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_to_df(model, cleaning, lemmatized):\n",
    "    \"\"\"\n",
    "    Appends model information into model summary dataframe for comparison\n",
    "    \"\"\"\n",
    "    df = pd.read_csv('../datasets/model_list_summary.csv')\n",
    "    \n",
    "    if lemmatized == 'no':\n",
    "        info = [cleaning,          #Indicates if data was minimally or deeply cleaned\n",
    "                lemmatized,        #Indicates if text was lemmatized or not\n",
    "                model.score(X_train,y_train), \n",
    "                model.score(X_test, y_test), \n",
    "                balanced_accuracy_score(y_train, model.predict(X_train)),\n",
    "                balanced_accuracy_score(y_test, model.predict(X_test)),\n",
    "                model.best_params_\n",
    "               ]\n",
    "    elif lemmatized == 'yes': \n",
    "        info = [cleaning,          #Indicates if data was minimally or deeply cleaned\n",
    "                lemmatized,        #Indicates if text was lemmatized or not\n",
    "                model.score(X_train_lem,y_train), \n",
    "                model.score(X_test_lem, y_test), \n",
    "                balanced_accuracy_score(y_train, model.predict(X_train_lem)),\n",
    "                balanced_accuracy_score(y_test, model.predict(X_test_lem)),\n",
    "                model.best_params_\n",
    "               ]\n",
    "    info_series = pd.Series(info, index=df.columns)\n",
    "    df = df.append(info_series, ignore_index=True)\n",
    "    df.to_csv('../datasets/model_list_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building my pipe and GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit_and_scores(model):\n",
    "    model.fit(X_train,y_train)\n",
    "    print(f' Score on train data:  {model.score(X_train,y_train)}')\n",
    "    print(f' Score on test data: {model.score(X_test, y_test)}')\n",
    "    print(f' balanced accuracy score on train data: {balanced_accuracy_score(y_train, model.predict(X_train))}')\n",
    "    print(f' balanced accuracy score on test data: {balanced_accuracy_score(y_test, model.predict(X_test))}')\n",
    "    print(model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(CountVectorizer(),\n",
    "                     MultinomialNB())\n",
    "params = { \n",
    "          'countvectorizer__stop_words': [None, 'english'], \n",
    "          'countvectorizer__max_features':[50, 150, 500, 1000],\n",
    "          'countvectorizer__ngram_range':[(1,2), (2,3)],\n",
    "          'multinomialnb__alpha':[.5, 1]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe,params, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Score on train data:  0.877080521817364\n",
      " Score on test data: 0.8782462057335582\n",
      " balanced accuracy score on train data: 0.8742356471890451\n",
      " balanced accuracy score on test data: 0.8751279320741716\n",
      "{'countvectorizer__max_features': 1000, 'countvectorizer__ngram_range': (1, 2), 'countvectorizer__stop_words': 'english', 'multinomialnb__alpha': 0.5}\n"
     ]
    }
   ],
   "source": [
    "model_fit_and_scores(gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the following is the best so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = make_pipeline(CountVectorizer(),\n",
    "                     MultinomialNB())\n",
    "params2 = { \n",
    "          'countvectorizer__stop_words': [None, 'english'], \n",
    "          'countvectorizer__max_features':[1000,3000],\n",
    "          'countvectorizer__ngram_range':[(1,2), (2,2)],\n",
    "          'multinomialnb__alpha':[.3, .5, .7]\n",
    "}\n",
    "\n",
    "gs2 = GridSearchCV(pipe2,params2, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Score on train data:  0.9114934772829509\n",
      " Score on test data: 0.8974704890387858\n",
      " balanced accuracy score on train data: 0.91034709756017\n",
      " balanced accuracy score on test data: 0.8955302767201855\n",
      "{'countvectorizer__max_features': 3000, 'countvectorizer__ngram_range': (1, 2), 'countvectorizer__stop_words': 'english', 'multinomialnb__alpha': 0.3}\n"
     ]
    }
   ],
   "source": [
    "model_fit_and_scores(gs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since this is the best so far using CountVectorizer, I will input this into my model summary\n",
    "\n",
    "input_to_df(gs2, 'deep', 'no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe3 = make_pipeline(CountVectorizer(),\n",
    "                     StandardScaler(with_mean=False),\n",
    "                     MultinomialNB())\n",
    "params3 = { \n",
    "          'countvectorizer__stop_words': [None, 'english'], \n",
    "          'countvectorizer__max_features':[3000,4000],\n",
    "          'countvectorizer__ngram_range':[(1,2), (1,1)],\n",
    "          'multinomialnb__alpha':[.1, .3]\n",
    "}\n",
    "\n",
    "gs3 = GridSearchCV(pipe3,params3, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Score on train data:  0.9201529464687359\n",
      " Score on test data: 0.890725126475548\n",
      " balanced accuracy score on train data: 0.9195007424033281\n",
      " balanced accuracy score on test data: 0.8896055592761923\n",
      "{'countvectorizer__max_features': 3000, 'countvectorizer__ngram_range': (1, 1), 'countvectorizer__stop_words': None, 'multinomialnb__alpha': 0.1}\n"
     ]
    }
   ],
   "source": [
    "model_fit_and_scores(gs3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe4 = make_pipeline(CountVectorizer(),\n",
    "                     StandardScaler(with_mean=False),\n",
    "                     MultinomialNB())\n",
    "params4 = { \n",
    "          'countvectorizer__stop_words': [None, 'english'], \n",
    "          'countvectorizer__max_features':[2700, 2800, 3000],\n",
    "          'countvectorizer__ngram_range':[(1,1), (1,2)],\n",
    "          'multinomialnb__alpha':[ .05, .1, .3]\n",
    "}\n",
    "\n",
    "gs4 = GridSearchCV(pipe4,params4, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Score on train data:  0.9186909581646424\n",
      " Score on test data: 0.8897133220910624\n",
      " balanced accuracy score on train data: 0.9179832899720628\n",
      " balanced accuracy score on test data: 0.8885436424553009\n",
      "{'countvectorizer__max_features': 2800, 'countvectorizer__ngram_range': (1, 1), 'countvectorizer__stop_words': None, 'multinomialnb__alpha': 0.05}\n"
     ]
    }
   ],
   "source": [
    "model_fit_and_scores(gs4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVectorizer - non-lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe10 = make_pipeline(TfidfVectorizer(),\n",
    "                     MultinomialNB())\n",
    "params10 = { \n",
    "          'tfidfvectorizer__stop_words': [None, 'english'], \n",
    "          'tfidfvectorizer__max_features':[3000, 3200],\n",
    "          'tfidfvectorizer__ngram_range':[(1,2), (1,1)],\n",
    "          'multinomialnb__alpha':[ .00005, .3]\n",
    "}\n",
    "\n",
    "gs10 = GridSearchCV(pipe10, params10, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Score on train data:  0.9237516869095816\n",
      " Score on test data: 0.9005059021922428\n",
      " balanced accuracy score on train data: 0.9220166946652195\n",
      " balanced accuracy score on test data: 0.8984901021337827\n",
      "{'multinomialnb__alpha': 0.3, 'tfidfvectorizer__max_features': 3200, 'tfidfvectorizer__ngram_range': (1, 1), 'tfidfvectorizer__stop_words': 'english'}\n"
     ]
    }
   ],
   "source": [
    "model_fit_and_scores(gs10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe11 = make_pipeline(TfidfVectorizer(),\n",
    "                     MultinomialNB())\n",
    "params11 = { \n",
    "          'tfidfvectorizer__stop_words': [None, 'english'], \n",
    "          'tfidfvectorizer__max_features':[3100, 3200,3300],\n",
    "          'tfidfvectorizer__ngram_range':[(1,2), (1,1)],\n",
    "          'multinomialnb__alpha':[ .1, .3, .5]\n",
    "}\n",
    "\n",
    "gs11 = GridSearchCV(pipe11, params11, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Score on train data:  0.9263382816014395\n",
      " Score on test data: 0.9021922428330523\n",
      " balanced accuracy score on train data: 0.9248478130787423\n",
      " balanced accuracy score on test data: 0.9003101690683966\n",
      "{'multinomialnb__alpha': 0.1, 'tfidfvectorizer__max_features': 3300, 'tfidfvectorizer__ngram_range': (1, 1), 'tfidfvectorizer__stop_words': 'english'}\n"
     ]
    }
   ],
   "source": [
    "model_fit_and_scores(gs11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe12 = make_pipeline(TfidfVectorizer(),\n",
    "                     MultinomialNB())\n",
    "params12 = { \n",
    "          'tfidfvectorizer__stop_words': ['english'], \n",
    "          'tfidfvectorizer__max_features':[3300,3350],\n",
    "          'tfidfvectorizer__ngram_range':[(1,1)],\n",
    "          'multinomialnb__alpha':[.04, .05,]\n",
    "}\n",
    "\n",
    "gs12 = GridSearchCV(pipe12, params12, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Score on train data:  0.9272379667116509\n",
      " Score on test data: 0.903204047217538\n",
      " balanced accuracy score on train data: 0.9257334737485723\n",
      " balanced accuracy score on test data: 0.9014473942389803\n",
      "{'multinomialnb__alpha': 0.05, 'tfidfvectorizer__max_features': 3300, 'tfidfvectorizer__ngram_range': (1, 1), 'tfidfvectorizer__stop_words': 'english'}\n"
     ]
    }
   ],
   "source": [
    "model_fit_and_scores(gs12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ^^ better than countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since this is the better than the CountVectorizer, I will input this into my model summary\n",
    "\n",
    "input_to_df(gs12, 'deep', 'no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_lem_fit_and_scores(model):\n",
    "    model.fit(X_train_lem,y_train)\n",
    "    print(f' Score on train data:  {model.score(X_train_lem,y_train)}')\n",
    "    print(f' Score on test data: {model.score(X_test_lem, y_test)}')\n",
    "    print(f' balanced accuracy score on train data: {balanced_accuracy_score(y_train, model.predict(X_train_lem))}')\n",
    "    print(f' balanced accuracy score on test data: {balanced_accuracy_score(y_test, model.predict(X_test_lem))}')\n",
    "    print(model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "def lemmatized(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    lemma_list = [token.lemma_ for token in doc]\n",
    "    lemma_sentence = ' '.join(lemma_list)\n",
    "    return lemma_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lem = X_train.apply(lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_lem = X_test.apply(lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe5 = make_pipeline(CountVectorizer(),\n",
    "                     MultinomialNB())\n",
    "params5 = { \n",
    "          'countvectorizer__stop_words': [None, 'english'], \n",
    "          'countvectorizer__max_features':[2800, 3000],\n",
    "          'countvectorizer__ngram_range':[(1,1), (1,2)],\n",
    "          'multinomialnb__alpha':[ .05, .1]\n",
    "}\n",
    "\n",
    "gs5 = GridSearchCV(pipe5, params5, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Score on train data:  0.9212775528565003\n",
      " Score on test data: 0.9075885328836425\n",
      " balanced accuracy score on train data: 0.9207893671558924\n",
      " balanced accuracy score on test data: 0.9069025284260233\n",
      "{'countvectorizer__max_features': 3000, 'countvectorizer__ngram_range': (1, 1), 'countvectorizer__stop_words': None, 'multinomialnb__alpha': 0.05}\n"
     ]
    }
   ],
   "source": [
    "model_lem_fit_and_scores(gs5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe6 = make_pipeline(CountVectorizer(),\n",
    "                     MultinomialNB())\n",
    "params6 = { \n",
    "          'countvectorizer__stop_words': [None, 'english'], \n",
    "          'countvectorizer__max_features':[3000,4000],\n",
    "          'countvectorizer__ngram_range':[(1,1), (2,2)],\n",
    "          'multinomialnb__alpha':[ .01, .05, .07]\n",
    "}\n",
    "\n",
    "gs6 = GridSearchCV(pipe6, params6, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Score on train data:  0.9324111560953666\n",
      " Score on test data: 0.9102866779089376\n",
      " balanced accuracy score on train data: 0.9312955456568446\n",
      " balanced accuracy score on test data: 0.908203036837989\n",
      "{'countvectorizer__max_features': 4000, 'countvectorizer__ngram_range': (1, 1), 'countvectorizer__stop_words': 'english', 'multinomialnb__alpha': 0.07}\n"
     ]
    }
   ],
   "source": [
    "model_lem_fit_and_scores(gs6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe7 = make_pipeline(CountVectorizer(),\n",
    "                     MultinomialNB())\n",
    "params7 = { \n",
    "          'countvectorizer__stop_words': [None, 'english'], \n",
    "          'countvectorizer__max_features':[4000,5000,6000],\n",
    "          'countvectorizer__ngram_range':[(1,1)],\n",
    "          'multinomialnb__alpha':[ .07, .08, .09]\n",
    "}\n",
    "\n",
    "gs7 = GridSearchCV(pipe7, params7, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Score on train data:  0.939608636977058\n",
      " Score on test data: 0.9129848229342327\n",
      " balanced accuracy score on train data: 0.9385811608530302\n",
      " balanced accuracy score on test data: 0.9114615623419562\n",
      "{'countvectorizer__max_features': 5000, 'countvectorizer__ngram_range': (1, 1), 'countvectorizer__stop_words': 'english', 'multinomialnb__alpha': 0.07}\n"
     ]
    }
   ],
   "source": [
    "model_lem_fit_and_scores(gs7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## better than tfidfvectorizer non-lemmatized^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will input this into my model summary\n",
    "\n",
    "input_to_df(gs7, 'deep', 'yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVectorizer - lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe8= make_pipeline(TfidfVectorizer(),\n",
    "                     MultinomialNB())\n",
    "params8 = { \n",
    "          'tfidfvectorizer__stop_words': ['english', None], \n",
    "          'tfidfvectorizer__max_features':[3000,4000],\n",
    "          'tfidfvectorizer__ngram_range':[(1,1), (1,2)],\n",
    "          'multinomialnb__alpha':[ .1, .5, 1]\n",
    "}\n",
    "\n",
    "gs8 = GridSearchCV(pipe8, params8, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Score on train data:  0.9345479082321188\n",
      " Score on test data: 0.9045531197301855\n",
      " balanced accuracy score on train data: 0.9334459420533654\n",
      " balanced accuracy score on test data: 0.9032649278651949\n",
      "{'multinomialnb__alpha': 0.5, 'tfidfvectorizer__max_features': 4000, 'tfidfvectorizer__ngram_range': (1, 1), 'tfidfvectorizer__stop_words': 'english'}\n"
     ]
    }
   ],
   "source": [
    "model_lem_fit_and_scores(gs8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe9= make_pipeline(TfidfVectorizer(),\n",
    "                     MultinomialNB())\n",
    "params9 = { \n",
    "          'tfidfvectorizer__stop_words': ['english'], \n",
    "          'tfidfvectorizer__max_features':[4000,5000],\n",
    "          'tfidfvectorizer__ngram_range':[(1,1), (2,2)],\n",
    "          'multinomialnb__alpha':[.8, .5, .3 ]\n",
    "}\n",
    "\n",
    "gs9 = GridSearchCV(pipe9, params9, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Score on train data:  0.9429824561403509\n",
      " Score on test data: 0.9059021922428331\n",
      " balanced accuracy score on train data: 0.9423218289622561\n",
      " balanced accuracy score on test data: 0.9049318447920246\n",
      "{'multinomialnb__alpha': 0.3, 'tfidfvectorizer__max_features': 5000, 'tfidfvectorizer__ngram_range': (1, 1), 'tfidfvectorizer__stop_words': 'english'}\n"
     ]
    }
   ],
   "source": [
    "model_lem_fit_and_scores(gs9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT better than countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But Since this is the best so far using TfidfVectorizer, I will input this into my model summary\n",
    "\n",
    "input_to_df(gs9, 'deep', 'yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking highest and lowest correlated words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = gs7.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/avhd/opt/anaconda3/envs/my_new_env/lib/python3.9/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute coef_ was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "coefs = best.named_steps['multinomialnb'].coef_\n",
    "vocab = best.named_steps['countvectorizer'].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame({'coefs': coefs[0], 'word': vocab})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefs</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>-3.425864</td>\n",
       "      <td>hike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4521</th>\n",
       "      <td>-3.977466</td>\n",
       "      <td>trail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2983</th>\n",
       "      <td>-4.096973</td>\n",
       "      <td>park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4657</th>\n",
       "      <td>-4.320086</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2696</th>\n",
       "      <td>-4.469873</td>\n",
       "      <td>mountain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2742</th>\n",
       "      <td>-4.537772</td>\n",
       "      <td>national</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>-4.730923</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2295</th>\n",
       "      <td>-4.795228</td>\n",
       "      <td>lake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>-4.898234</td>\n",
       "      <td>fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4190</th>\n",
       "      <td>-4.933730</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         coefs      word\n",
       "1932 -3.425864      hike\n",
       "4521 -3.977466     trail\n",
       "2983 -4.096973      park\n",
       "4657 -4.320086       usa\n",
       "2696 -4.469873  mountain\n",
       "2742 -4.537772  national\n",
       "1074 -4.730923       day\n",
       "2295 -4.795228      lake\n",
       "1448 -4.898234      fall\n",
       "4190 -4.933730     state"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df.nlargest(10,'coefs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefs</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-13.110724</td>\n",
       "      <td>acclimate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-13.110724</td>\n",
       "      <td>accord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-13.110724</td>\n",
       "      <td>accordingly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-13.110724</td>\n",
       "      <td>acid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-13.110724</td>\n",
       "      <td>adapt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-13.110724</td>\n",
       "      <td>addition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-13.110724</td>\n",
       "      <td>address</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-13.110724</td>\n",
       "      <td>adhere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>-13.110724</td>\n",
       "      <td>advertising</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>-13.110724</td>\n",
       "      <td>aerogarden</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        coefs         word\n",
       "14 -13.110724    acclimate\n",
       "16 -13.110724       accord\n",
       "17 -13.110724  accordingly\n",
       "22 -13.110724         acid\n",
       "36 -13.110724        adapt\n",
       "39 -13.110724     addition\n",
       "41 -13.110724      address\n",
       "42 -13.110724       adhere\n",
       "55 -13.110724  advertising\n",
       "59 -13.110724   aerogarden"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df.nsmallest(10,'coefs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
