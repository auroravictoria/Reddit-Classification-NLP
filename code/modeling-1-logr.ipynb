{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling - Logistic Regression (after minimal data cleaning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before any extensive data cleaning and preprocessing, this is the model I initially created. Note that only the following were done before modeling:\n",
    "- Dropped \"deleted\" postings\n",
    "- Still had duplicate postings\n",
    "- No engineering of any features before modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After dropping deleted posts, I had the following remaining number of posts to use for this model:\n",
    "\n",
    "- hiking       - 6,986\n",
    "- gardening    - 5,467\n",
    "- total - 12,453"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import plot_confusion_matrix, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data\n",
    "\n",
    "postings = pd.read_csv('../datasets/postings_minimally_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hiking</td>\n",
       "      <td>Boulder Flatiron Loop Hike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hiking</td>\n",
       "      <td>Washington state lakes to swim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hiking</td>\n",
       "      <td>Here's a fun episode, demonstrating why a fly-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hiking</td>\n",
       "      <td>Picture I took of my friend at Angel’s Landing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hiking</td>\n",
       "      <td>Hiking to Bertha Peak via Cougar Crest Trail a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12448</th>\n",
       "      <td>gardening</td>\n",
       "      <td>Nope haha Oklahoma so not too far away.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12449</th>\n",
       "      <td>gardening</td>\n",
       "      <td>I'm transitioning to everbearing in strawberry...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12450</th>\n",
       "      <td>gardening</td>\n",
       "      <td>So pretty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12451</th>\n",
       "      <td>gardening</td>\n",
       "      <td>I think it’s 30% chance of frost after that date.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12452</th>\n",
       "      <td>gardening</td>\n",
       "      <td>My understanding is that the caterpillars eat ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12453 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           topic                                               text\n",
       "0         hiking                         Boulder Flatiron Loop Hike\n",
       "1         hiking                     Washington state lakes to swim\n",
       "2         hiking  Here's a fun episode, demonstrating why a fly-...\n",
       "3         hiking  Picture I took of my friend at Angel’s Landing...\n",
       "4         hiking  Hiking to Bertha Peak via Cougar Crest Trail a...\n",
       "...          ...                                                ...\n",
       "12448  gardening            Nope haha Oklahoma so not too far away.\n",
       "12449  gardening  I'm transitioning to everbearing in strawberry...\n",
       "12450  gardening                                          So pretty\n",
       "12451  gardening  I think it’s 30% chance of frost after that date.\n",
       "12452  gardening  My understanding is that the caterpillars eat ...\n",
       "\n",
       "[12453 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define X and y\n",
    "\n",
    "X = postings['text']\n",
    "y = np.where(postings['topic'] == 'hiking',1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                               Boulder Flatiron Loop Hike\n",
       "1                           Washington state lakes to swim\n",
       "2        Here's a fun episode, demonstrating why a fly-...\n",
       "3        Picture I took of my friend at Angel’s Landing...\n",
       "4        Hiking to Bertha Peak via Cougar Crest Trail a...\n",
       "                               ...                        \n",
       "12448              Nope haha Oklahoma so not too far away.\n",
       "12449    I'm transitioning to everbearing in strawberry...\n",
       "12450                                            So pretty\n",
       "12451    I think it’s 30% chance of frost after that date.\n",
       "12452    My understanding is that the caterpillars eat ...\n",
       "Name: text, Length: 12453, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking X\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking y\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6986"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y)  #this should be 6986 (number of hiking rows) -- confirmed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, test, split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, stratify=y, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a null model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.560989\n",
       "0    0.439011\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have to create a model that does better than the 56% accuracy rate of the null model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a dataframe where I can save scores and best parameters for comparison\n",
    "\n",
    "df = pd.DataFrame(columns=('data_cleaning', 'lemmatized', 'train_acc', 'test_acc', 'train_bal_acc', 'test_bal_acc', 'params'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_cleaning</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>train_bal_acc</th>\n",
       "      <th>test_bal_acc</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [data_cleaning, lemmatized, train_acc, test_acc, train_bal_acc, test_bal_acc, params]\n",
       "Index: []"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check empty dataframe\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save empty dataframe as csv\n",
    "\n",
    "df.to_csv('../datasets/model_list_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_cleaning</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>train_bal_acc</th>\n",
       "      <th>test_bal_acc</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [data_cleaning, lemmatized, train_acc, test_acc, train_bal_acc, test_bal_acc, params]\n",
       "Index: []"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in empty csv and check it works\n",
    "\n",
    "df = pd.read_csv('../datasets/model_list_summary.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to save model information to my dataframe; \n",
    "# Note that I will call this function only when the model results are worth saving, not for every fitting and scoring.\n",
    "\n",
    "def input_to_df(model, cleaning, lemmatized):\n",
    "    \"\"\"\n",
    "    Appends model information into model summary dataframe for comparison\n",
    "    \"\"\"\n",
    "    df = pd.read_csv('../datasets/model_list_summary.csv')\n",
    "    \n",
    "    if lemmatized == 'no':\n",
    "        info = [cleaning,          #Indicates if data was minimally or deeply cleaned\n",
    "                lemmatized,        #Indicates if text was lemmatized or not\n",
    "                model.score(X_train,y_train), \n",
    "                model.score(X_test, y_test), \n",
    "                balanced_accuracy_score(y_train, model.predict(X_train)),\n",
    "                balanced_accuracy_score(y_test, model.predict(X_test)),\n",
    "                model.best_params_\n",
    "               ]\n",
    "    elif lemmatized == 'yes': \n",
    "        info = [cleaning,          #Indicates if data was minimally or deeply cleaned\n",
    "                lemmatized,        #Indicates if text was lemmatized or not\n",
    "                model.score(X_train_lem,y_train), \n",
    "                model.score(X_test_lem, y_test), \n",
    "                balanced_accuracy_score(y_train, model.predict(X_train_lem)),\n",
    "                balanced_accuracy_score(y_test, model.predict(X_test_lem)),\n",
    "                model.best_params_\n",
    "               ]\n",
    "    info_series = pd.Series(info, index=df.columns)\n",
    "    df = df.append(info_series, ignore_index=True)\n",
    "    df.to_csv('../datasets/model_list_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building my pipe and GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I will look into balanced accuracy score as well since I would like to make sure my model does well on\n",
    "#predicting both subreddit topics.\n",
    "\n",
    "def model_fit_and_scores(model):\n",
    "    model.fit(X_train,y_train)\n",
    "    print(f' accuracy score on train data:  {model.score(X_train,y_train)}')\n",
    "    print(f' accuracy score on test data: {model.score(X_test, y_test)}')\n",
    "    print(f' balanced accuracy score on train data: {balanced_accuracy_score(y_train, model.predict(X_train))}')\n",
    "    print(f' balanced accuracy score on test data: {balanced_accuracy_score(y_test, model.predict(X_test))}')\n",
    "    print(model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(CountVectorizer(),\n",
    "                     StandardScaler(with_mean=False),\n",
    "                     LogisticRegression(max_iter=10000))\n",
    "params = { \n",
    "          'countvectorizer__stop_words': [None, 'english'], \n",
    "          'countvectorizer__max_features':[50, 150, 500, 1000],\n",
    "          'countvectorizer__ngram_range':[(1,2), (2,3)],\n",
    "          'logisticregression__C':[.01, 50, 250, 1000]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe,params, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " accuracy score on train data:  0.912089088767534\n",
      " accuracy score on test data: 0.8831085420680796\n",
      " balanced accuracy score on train data: 0.9148579835101653\n",
      " balanced accuracy score on test data: 0.8857969079818722\n",
      "{'countvectorizer__max_features': 1000, 'countvectorizer__ngram_range': (1, 2), 'countvectorizer__stop_words': 'english', 'logisticregression__C': 0.01}\n"
     ]
    }
   ],
   "source": [
    "model_fit_and_scores(gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = make_pipeline(CountVectorizer(),\n",
    "                     StandardScaler(with_mean=False),\n",
    "                     LogisticRegression(max_iter=10000))\n",
    "params2 = { \n",
    "          'countvectorizer__stop_words': [None, 'english'], \n",
    "          'countvectorizer__max_features':[900, 1000, 5000],\n",
    "          'countvectorizer__ngram_range':[(1,1), (1,2), (2,2)],\n",
    "          'logisticregression__C':[.005, .01, .02]\n",
    "}\n",
    "\n",
    "gs2 = GridSearchCV(pipe2, params2, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/avhd/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Score on train data:  0.9744714349977508\n",
      " Score on test data: 0.9069139966273188\n",
      " Score on entire data: 0.9575778021421945\n",
      "{'countvectorizer__max_features': 5000, 'countvectorizer__ngram_range': (1, 1), 'countvectorizer__stop_words': None, 'logisticregression__C': 0.005}\n"
     ]
    }
   ],
   "source": [
    "model_fit_and_scores(gs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe3 = make_pipeline(CountVectorizer(),\n",
    "                     StandardScaler(with_mean=False),\n",
    "                     LogisticRegression(max_iter=10000))\n",
    "params3 = { \n",
    "          'countvectorizer__stop_words': [None, 'english'], \n",
    "          'countvectorizer__max_features':[4500, 5000, 6000, 8000],\n",
    "          'countvectorizer__ngram_range':[(1,1), (1,2), (2,2)],\n",
    "          'logisticregression__C':[.0001, .0005, .001, .005, .01]\n",
    "}\n",
    "\n",
    "gs3 = GridSearchCV(pipe3, params3, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Score on train data:  0.9690545026234072\n",
      " Score on test data: 0.8917790622992935\n",
      " Score on entire data: 0.9497309885168232\n",
      "{'countvectorizer__max_features': 4500, 'countvectorizer__ngram_range': (1, 1), 'countvectorizer__stop_words': 'english', 'logisticregression__C': 0.005}\n"
     ]
    }
   ],
   "source": [
    "model_fit_and_scores(gs3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe4 = make_pipeline(CountVectorizer(),\n",
    "                     StandardScaler(with_mean=False),\n",
    "                     LogisticRegression(max_iter=10000))\n",
    "params4 = { \n",
    "          'countvectorizer__stop_words': [None, 'english'], \n",
    "          'countvectorizer__max_features':[4500, 5500, 6000, 6500, 7000],\n",
    "          'countvectorizer__ngram_range':[(1,1), (1,2), (2,2)],\n",
    "          'logisticregression__C':[.0005, .001, .005]\n",
    "}\n",
    "\n",
    "gs4 = GridSearchCV(pipe4, params4, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Score on train data:  0.9690545026234072\n",
      " Score on test data: 0.8917790622992935\n",
      " Score on entire data: 0.9497309885168232\n",
      "{'countvectorizer__max_features': 4500, 'countvectorizer__ngram_range': (1, 1), 'countvectorizer__stop_words': 'english', 'logisticregression__C': 0.005}\n"
     ]
    }
   ],
   "source": [
    "model_fit_and_scores(gs4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe5 = make_pipeline(CountVectorizer(),\n",
    "                     StandardScaler(with_mean=False),\n",
    "                     LogisticRegression(max_iter=10000))\n",
    "params5 = { \n",
    "          'countvectorizer__stop_words': [None, 'english'], \n",
    "          'countvectorizer__max_features':[4000, 4500, 5000],\n",
    "          'countvectorizer__ngram_range':[(1,1)],\n",
    "          'logisticregression__C':[.001, .005]\n",
    "}\n",
    "\n",
    "gs5 = GridSearchCV(pipe5, params5, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " accuracy score on train data:  0.9596316522111575\n",
      " accuracy score on test data: 0.9020552344251767\n",
      " balanced accuracy score on train data: 0.9569938640310244\n",
      " balanced accuracy score on test data: 0.897909426924367\n",
      "{'countvectorizer__max_features': 5000, 'countvectorizer__ngram_range': (1, 1), 'countvectorizer__stop_words': None, 'logisticregression__C': 0.001}\n"
     ]
    }
   ],
   "source": [
    "model_fit_and_scores(gs5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fcdd402bc70>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(gs5, X_test,y_test, display_labels=('gardening','hiking'), cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since this is the best so far using CountVectorizer, I will input this into my model summary\n",
    "\n",
    "input_to_df(gs5, 'minimal', 'no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Countvectorizer model  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Score on train data:  0.9596316522111575\n",
    "- Score on test data: 0.9020552344251767\n",
    "- Parameters:\n",
    "    - countvectorizer__max_features: 5000\n",
    "    - countvectorizer__ngram_range: (1, 1)\n",
    "    - countvectorizer__stop_words: None\n",
    "    - logisticregression__C: 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_countvectorizer__max_features</th>\n",
       "      <th>param_countvectorizer__ngram_range</th>\n",
       "      <th>param_countvectorizer__stop_words</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.229512</td>\n",
       "      <td>0.004292</td>\n",
       "      <td>0.036296</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>4000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'countvectorizer__max_features': 4000, 'count...</td>\n",
       "      <td>0.894540</td>\n",
       "      <td>0.889722</td>\n",
       "      <td>0.887580</td>\n",
       "      <td>0.891863</td>\n",
       "      <td>0.904124</td>\n",
       "      <td>0.893566</td>\n",
       "      <td>0.005761</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.218464</td>\n",
       "      <td>0.031928</td>\n",
       "      <td>0.033798</td>\n",
       "      <td>0.003194</td>\n",
       "      <td>4000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.005</td>\n",
       "      <td>{'countvectorizer__max_features': 4000, 'count...</td>\n",
       "      <td>0.896681</td>\n",
       "      <td>0.887045</td>\n",
       "      <td>0.892934</td>\n",
       "      <td>0.891328</td>\n",
       "      <td>0.897697</td>\n",
       "      <td>0.893137</td>\n",
       "      <td>0.003841</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.170040</td>\n",
       "      <td>0.024149</td>\n",
       "      <td>0.029346</td>\n",
       "      <td>0.003140</td>\n",
       "      <td>4000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'countvectorizer__max_features': 4000, 'count...</td>\n",
       "      <td>0.888651</td>\n",
       "      <td>0.881692</td>\n",
       "      <td>0.891328</td>\n",
       "      <td>0.889186</td>\n",
       "      <td>0.896090</td>\n",
       "      <td>0.889389</td>\n",
       "      <td>0.004658</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.172586</td>\n",
       "      <td>0.021783</td>\n",
       "      <td>0.030955</td>\n",
       "      <td>0.006263</td>\n",
       "      <td>4000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.005</td>\n",
       "      <td>{'countvectorizer__max_features': 4000, 'count...</td>\n",
       "      <td>0.890257</td>\n",
       "      <td>0.892398</td>\n",
       "      <td>0.892934</td>\n",
       "      <td>0.890792</td>\n",
       "      <td>0.890734</td>\n",
       "      <td>0.891423</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.188525</td>\n",
       "      <td>0.020840</td>\n",
       "      <td>0.030522</td>\n",
       "      <td>0.003319</td>\n",
       "      <td>4500</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'countvectorizer__max_features': 4500, 'count...</td>\n",
       "      <td>0.892398</td>\n",
       "      <td>0.889186</td>\n",
       "      <td>0.885439</td>\n",
       "      <td>0.891328</td>\n",
       "      <td>0.904124</td>\n",
       "      <td>0.892495</td>\n",
       "      <td>0.006282</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.195320</td>\n",
       "      <td>0.004498</td>\n",
       "      <td>0.037246</td>\n",
       "      <td>0.002814</td>\n",
       "      <td>4500</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.005</td>\n",
       "      <td>{'countvectorizer__max_features': 4500, 'count...</td>\n",
       "      <td>0.897216</td>\n",
       "      <td>0.890257</td>\n",
       "      <td>0.891328</td>\n",
       "      <td>0.889186</td>\n",
       "      <td>0.898232</td>\n",
       "      <td>0.893244</td>\n",
       "      <td>0.003734</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.169137</td>\n",
       "      <td>0.005280</td>\n",
       "      <td>0.029167</td>\n",
       "      <td>0.007317</td>\n",
       "      <td>4500</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'countvectorizer__max_features': 4500, 'count...</td>\n",
       "      <td>0.890257</td>\n",
       "      <td>0.880621</td>\n",
       "      <td>0.888651</td>\n",
       "      <td>0.889722</td>\n",
       "      <td>0.900911</td>\n",
       "      <td>0.890032</td>\n",
       "      <td>0.006465</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.178086</td>\n",
       "      <td>0.006137</td>\n",
       "      <td>0.032455</td>\n",
       "      <td>0.010847</td>\n",
       "      <td>4500</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.005</td>\n",
       "      <td>{'countvectorizer__max_features': 4500, 'count...</td>\n",
       "      <td>0.891328</td>\n",
       "      <td>0.889722</td>\n",
       "      <td>0.889186</td>\n",
       "      <td>0.890257</td>\n",
       "      <td>0.892341</td>\n",
       "      <td>0.890567</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.185128</td>\n",
       "      <td>0.008162</td>\n",
       "      <td>0.033299</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'countvectorizer__max_features': 5000, 'count...</td>\n",
       "      <td>0.890257</td>\n",
       "      <td>0.889722</td>\n",
       "      <td>0.890792</td>\n",
       "      <td>0.892934</td>\n",
       "      <td>0.906267</td>\n",
       "      <td>0.893994</td>\n",
       "      <td>0.006232</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.201129</td>\n",
       "      <td>0.010668</td>\n",
       "      <td>0.032075</td>\n",
       "      <td>0.002612</td>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.005</td>\n",
       "      <td>{'countvectorizer__max_features': 5000, 'count...</td>\n",
       "      <td>0.890257</td>\n",
       "      <td>0.894540</td>\n",
       "      <td>0.891863</td>\n",
       "      <td>0.891328</td>\n",
       "      <td>0.898768</td>\n",
       "      <td>0.893351</td>\n",
       "      <td>0.003054</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.176199</td>\n",
       "      <td>0.008190</td>\n",
       "      <td>0.031440</td>\n",
       "      <td>0.002169</td>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'countvectorizer__max_features': 5000, 'count...</td>\n",
       "      <td>0.890792</td>\n",
       "      <td>0.883298</td>\n",
       "      <td>0.891863</td>\n",
       "      <td>0.887045</td>\n",
       "      <td>0.900375</td>\n",
       "      <td>0.890675</td>\n",
       "      <td>0.005712</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.144774</td>\n",
       "      <td>0.014917</td>\n",
       "      <td>0.022001</td>\n",
       "      <td>0.002913</td>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.005</td>\n",
       "      <td>{'countvectorizer__max_features': 5000, 'count...</td>\n",
       "      <td>0.890792</td>\n",
       "      <td>0.891328</td>\n",
       "      <td>0.888116</td>\n",
       "      <td>0.884904</td>\n",
       "      <td>0.892876</td>\n",
       "      <td>0.889603</td>\n",
       "      <td>0.002807</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.229512      0.004292         0.036296        0.001047   \n",
       "1        0.218464      0.031928         0.033798        0.003194   \n",
       "2        0.170040      0.024149         0.029346        0.003140   \n",
       "3        0.172586      0.021783         0.030955        0.006263   \n",
       "4        0.188525      0.020840         0.030522        0.003319   \n",
       "5        0.195320      0.004498         0.037246        0.002814   \n",
       "6        0.169137      0.005280         0.029167        0.007317   \n",
       "7        0.178086      0.006137         0.032455        0.010847   \n",
       "8        0.185128      0.008162         0.033299        0.005075   \n",
       "9        0.201129      0.010668         0.032075        0.002612   \n",
       "10       0.176199      0.008190         0.031440        0.002169   \n",
       "11       0.144774      0.014917         0.022001        0.002913   \n",
       "\n",
       "   param_countvectorizer__max_features param_countvectorizer__ngram_range  \\\n",
       "0                                 4000                             (1, 1)   \n",
       "1                                 4000                             (1, 1)   \n",
       "2                                 4000                             (1, 1)   \n",
       "3                                 4000                             (1, 1)   \n",
       "4                                 4500                             (1, 1)   \n",
       "5                                 4500                             (1, 1)   \n",
       "6                                 4500                             (1, 1)   \n",
       "7                                 4500                             (1, 1)   \n",
       "8                                 5000                             (1, 1)   \n",
       "9                                 5000                             (1, 1)   \n",
       "10                                5000                             (1, 1)   \n",
       "11                                5000                             (1, 1)   \n",
       "\n",
       "   param_countvectorizer__stop_words param_logisticregression__C  \\\n",
       "0                               None                       0.001   \n",
       "1                               None                       0.005   \n",
       "2                            english                       0.001   \n",
       "3                            english                       0.005   \n",
       "4                               None                       0.001   \n",
       "5                               None                       0.005   \n",
       "6                            english                       0.001   \n",
       "7                            english                       0.005   \n",
       "8                               None                       0.001   \n",
       "9                               None                       0.005   \n",
       "10                           english                       0.001   \n",
       "11                           english                       0.005   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'countvectorizer__max_features': 4000, 'count...           0.894540   \n",
       "1   {'countvectorizer__max_features': 4000, 'count...           0.896681   \n",
       "2   {'countvectorizer__max_features': 4000, 'count...           0.888651   \n",
       "3   {'countvectorizer__max_features': 4000, 'count...           0.890257   \n",
       "4   {'countvectorizer__max_features': 4500, 'count...           0.892398   \n",
       "5   {'countvectorizer__max_features': 4500, 'count...           0.897216   \n",
       "6   {'countvectorizer__max_features': 4500, 'count...           0.890257   \n",
       "7   {'countvectorizer__max_features': 4500, 'count...           0.891328   \n",
       "8   {'countvectorizer__max_features': 5000, 'count...           0.890257   \n",
       "9   {'countvectorizer__max_features': 5000, 'count...           0.890257   \n",
       "10  {'countvectorizer__max_features': 5000, 'count...           0.890792   \n",
       "11  {'countvectorizer__max_features': 5000, 'count...           0.890792   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.889722           0.887580           0.891863   \n",
       "1            0.887045           0.892934           0.891328   \n",
       "2            0.881692           0.891328           0.889186   \n",
       "3            0.892398           0.892934           0.890792   \n",
       "4            0.889186           0.885439           0.891328   \n",
       "5            0.890257           0.891328           0.889186   \n",
       "6            0.880621           0.888651           0.889722   \n",
       "7            0.889722           0.889186           0.890257   \n",
       "8            0.889722           0.890792           0.892934   \n",
       "9            0.894540           0.891863           0.891328   \n",
       "10           0.883298           0.891863           0.887045   \n",
       "11           0.891328           0.888116           0.884904   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.904124         0.893566        0.005761                2  \n",
       "1            0.897697         0.893137        0.003841                5  \n",
       "2            0.896090         0.889389        0.004658               12  \n",
       "3            0.890734         0.891423        0.001046                7  \n",
       "4            0.904124         0.892495        0.006282                6  \n",
       "5            0.898232         0.893244        0.003734                4  \n",
       "6            0.900911         0.890032        0.006465               10  \n",
       "7            0.892341         0.890567        0.001135                9  \n",
       "8            0.906267         0.893994        0.006232                1  \n",
       "9            0.898768         0.893351        0.003054                3  \n",
       "10           0.900375         0.890675        0.005712                8  \n",
       "11           0.892876         0.889603        0.002807               11  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs5.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVectorizer does slightly better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe20 = make_pipeline(TfidfVectorizer(),\n",
    "                     StandardScaler(with_mean=False),\n",
    "                    LogisticRegression(max_iter=10000))\n",
    "params20 = { \n",
    "          'tfidfvectorizer__stop_words': [None, 'english'], \n",
    "          'tfidfvectorizer__max_features':[4000,5000],\n",
    "          'tfidfvectorizer__ngram_range':[(1,1),(1,2)],\n",
    "          'logisticregression__C':[.001, .005]\n",
    "}\n",
    "\n",
    "gs20 = GridSearchCV(pipe20, params20, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " accuracy score on train data:  0.9688403469322198\n",
      " accuracy score on test data: 0.9020552344251767\n",
      " balanced accuracy score on train data: 0.9671635110033101\n",
      " balanced accuracy score on test data: 0.8987845816990481\n",
      "{'logisticregression__C': 0.001, 'tfidfvectorizer__max_features': 5000, 'tfidfvectorizer__ngram_range': (1, 1), 'tfidfvectorizer__stop_words': None}\n"
     ]
    }
   ],
   "source": [
    "model_fit_and_scores(gs20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since TfidfVectorizer did slightly better than the best CountVectorizer model, I will input this into my model summary\n",
    "\n",
    "input_to_df(gs20, 'minimal', 'no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking highest and lowest correlated words..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = gs20.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = best.named_steps['logisticregression'].coef_\n",
    "vocab = best.named_steps['tfidfvectorizer'].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame({'coefs': coefs[0], 'word': vocab})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefs</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1933</th>\n",
       "      <td>0.198537</td>\n",
       "      <td>hiking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>0.183930</td>\n",
       "      <td>hike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4561</th>\n",
       "      <td>0.140328</td>\n",
       "      <td>trail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>0.121242</td>\n",
       "      <td>park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4692</th>\n",
       "      <td>0.100061</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2312</th>\n",
       "      <td>0.091811</td>\n",
       "      <td>lake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2788</th>\n",
       "      <td>0.091624</td>\n",
       "      <td>mountain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2840</th>\n",
       "      <td>0.082691</td>\n",
       "      <td>national</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2789</th>\n",
       "      <td>0.081796</td>\n",
       "      <td>mountains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>0.079084</td>\n",
       "      <td>falls</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         coefs       word\n",
       "1933  0.198537     hiking\n",
       "1926  0.183930       hike\n",
       "4561  0.140328      trail\n",
       "3131  0.121242       park\n",
       "4692  0.100061        usa\n",
       "2312  0.091811       lake\n",
       "2788  0.091624   mountain\n",
       "2840  0.082691   national\n",
       "2789  0.081796  mountains\n",
       "1420  0.079084      falls"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df.nlargest(10,'coefs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefs</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>-0.148755</td>\n",
       "      <td>garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3303</th>\n",
       "      <td>-0.131526</td>\n",
       "      <td>plant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3310</th>\n",
       "      <td>-0.111980</td>\n",
       "      <td>plants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>-0.095615</td>\n",
       "      <td>gardening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>-0.091510</td>\n",
       "      <td>grow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2818</th>\n",
       "      <td>-0.090062</td>\n",
       "      <td>my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4451</th>\n",
       "      <td>-0.078420</td>\n",
       "      <td>they</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>-0.075742</td>\n",
       "      <td>flowers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>-0.075234</td>\n",
       "      <td>growing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4126</th>\n",
       "      <td>-0.075117</td>\n",
       "      <td>soil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         coefs       word\n",
       "1626 -0.148755     garden\n",
       "3303 -0.131526      plant\n",
       "3310 -0.111980     plants\n",
       "1630 -0.095615  gardening\n",
       "1763 -0.091510       grow\n",
       "2818 -0.090062         my\n",
       "4451 -0.078420       they\n",
       "1525 -0.075742    flowers\n",
       "1764 -0.075234    growing\n",
       "4126 -0.075117       soil"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df.nsmallest(10,'coefs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
