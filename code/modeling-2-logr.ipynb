{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling - Logistic Regression (after deep data cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer,  TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import plot_confusion_matrix, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data\n",
    "\n",
    "postings = pd.read_csv('../datasets/postings_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hiking</td>\n",
       "      <td>boulder flatiron loop hike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hiking</td>\n",
       "      <td>washington state lakes to swim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hiking</td>\n",
       "      <td>here a fun episode demonstrating why a is a fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hiking</td>\n",
       "      <td>picture i took of my friend at angel s landing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hiking</td>\n",
       "      <td>hiking to bertha peak via cougar crest trail a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11852</th>\n",
       "      <td>gardening</td>\n",
       "      <td>nope haha oklahoma so not too far away</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11853</th>\n",
       "      <td>gardening</td>\n",
       "      <td>i transitioning to everbearing in strawberry p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11854</th>\n",
       "      <td>gardening</td>\n",
       "      <td>so pretty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11855</th>\n",
       "      <td>gardening</td>\n",
       "      <td>i think it s chance of frost after that date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11856</th>\n",
       "      <td>gardening</td>\n",
       "      <td>my understanding is that the caterpillars eat ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11857 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           topic                                               text\n",
       "0         hiking                         boulder flatiron loop hike\n",
       "1         hiking                     washington state lakes to swim\n",
       "2         hiking  here a fun episode demonstrating why a is a fo...\n",
       "3         hiking  picture i took of my friend at angel s landing...\n",
       "4         hiking  hiking to bertha peak via cougar crest trail a...\n",
       "...          ...                                                ...\n",
       "11852  gardening             nope haha oklahoma so not too far away\n",
       "11853  gardening  i transitioning to everbearing in strawberry p...\n",
       "11854  gardening                                          so pretty\n",
       "11855  gardening       i think it s chance of frost after that date\n",
       "11856  gardening  my understanding is that the caterpillars eat ...\n",
       "\n",
       "[11857 rows x 2 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define X and y\n",
    "\n",
    "X = postings['text']\n",
    "y = np.where(postings['topic'] == 'hiking',1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                               boulder flatiron loop hike\n",
       "1                           washington state lakes to swim\n",
       "2        here a fun episode demonstrating why a is a fo...\n",
       "3        picture i took of my friend at angel s landing...\n",
       "4        hiking to bertha peak via cougar crest trail a...\n",
       "                               ...                        \n",
       "11852               nope haha oklahoma so not too far away\n",
       "11853    i transitioning to everbearing in strawberry p...\n",
       "11854                                            so pretty\n",
       "11855         i think it s chance of frost after that date\n",
       "11856    my understanding is that the caterpillars eat ...\n",
       "Name: text, Length: 11857, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking X\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking y\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, test, split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, stratify=y, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a null model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.555031\n",
       "0    0.444969\n",
       "dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have to create a model that does bettern than the 56% rate of the null model\n",
    "# This didn't change much after deep cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_to_df(model, cleaning, lemmatized):\n",
    "    \"\"\"\n",
    "    Appends model information into model summary dataframe for comparison\n",
    "    \"\"\"\n",
    "    df = pd.read_csv('../datasets/model_list_summary.csv')\n",
    "    \n",
    "    if lemmatized == 'no':\n",
    "        info = [cleaning,          #Indicates if data was minimally or deeply cleaned\n",
    "                lemmatized,        #Indicates if text was lemmatized or not\n",
    "                model.score(X_train,y_train), \n",
    "                model.score(X_test, y_test), \n",
    "                balanced_accuracy_score(y_train, model.predict(X_train)),\n",
    "                balanced_accuracy_score(y_test, model.predict(X_test)),\n",
    "                model.best_params_\n",
    "               ]\n",
    "    elif lemmatized == 'yes': \n",
    "        info = [cleaning,          #Indicates if data was minimally or deeply cleaned\n",
    "                lemmatized,        #Indicates if text was lemmatized or not\n",
    "                model.score(X_train_lem,y_train), \n",
    "                model.score(X_test_lem, y_test), \n",
    "                balanced_accuracy_score(y_train, model.predict(X_train_lem)),\n",
    "                balanced_accuracy_score(y_test, model.predict(X_test_lem)),\n",
    "                model.best_params_\n",
    "               ]\n",
    "    info_series = pd.Series(info, index=df.columns)\n",
    "    df = df.append(info_series, ignore_index=True)\n",
    "    df.to_csv('../datasets/model_list_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building my pipe and GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit_and_scores(model):\n",
    "    model.fit(X_train,y_train)\n",
    "    print(f' accuracy score on train data:  {model.score(X_train,y_train)}')\n",
    "    print(f' accuracy score on test data: {model.score(X_test, y_test)}')\n",
    "    print(f' balanced accuracy score on train data: {balanced_accuracy_score(y_train, model.predict(X_train))}')\n",
    "    print(f' balanced accuracy score on test data: {balanced_accuracy_score(y_test, model.predict(X_test))}')\n",
    "    print(model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe5 = make_pipeline(CountVectorizer(),\n",
    "                     StandardScaler(with_mean=False),\n",
    "                     LogisticRegression())\n",
    "params5 = { \n",
    "          'countvectorizer__stop_words': [None, 'english'], \n",
    "          'countvectorizer__max_features':[4000,5000],\n",
    "          'countvectorizer__ngram_range':[(1,1), (1,2), (2,2)],\n",
    "          'logisticregression__C':[.001, .01, .1]\n",
    "}\n",
    "\n",
    "gs5 = GridSearchCV(pipe5,params5, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " accuracy score on train data:  0.9613135402609086\n",
      " accuracy score on test data: 0.8978077571669477\n",
      " balanced accuracy score on train data: 0.9593373445388995\n",
      " balanced accuracy score on test data: 0.8948550348813537\n",
      "{'countvectorizer__max_features': 5000, 'countvectorizer__ngram_range': (1, 1), 'countvectorizer__stop_words': 'english', 'logisticregression__C': 0.001}\n"
     ]
    }
   ],
   "source": [
    "model_fit_and_scores(gs5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe6 = make_pipeline(CountVectorizer(),\n",
    "                     StandardScaler(with_mean=False),\n",
    "                     LogisticRegression())\n",
    "params6 = { \n",
    "          'countvectorizer__stop_words': ['english'], \n",
    "          'countvectorizer__max_features':[4500,5000,5500],\n",
    "          'countvectorizer__ngram_range':[(1,1), (1,2)],\n",
    "          'logisticregression__C':[.0008, .001, .002]\n",
    "}\n",
    "\n",
    "gs6 = GridSearchCV(pipe6,params6, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " accuracy score on train data:  0.9560278902384165\n",
      " accuracy score on test data: 0.897133220910624\n",
      " balanced accuracy score on train data: 0.9536739555080336\n",
      " balanced accuracy score on test data: 0.8933438012707076\n",
      "{'countvectorizer__max_features': 4500, 'countvectorizer__ngram_range': (1, 1), 'countvectorizer__stop_words': 'english', 'logisticregression__C': 0.0008}\n"
     ]
    }
   ],
   "source": [
    "model_fit_and_scores(gs6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since this is the best so far, I will input this into my model summary\n",
    "\n",
    "input_to_df(gs6, 'deep', 'no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatized did better than non-lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created a new function for lemmatized data\n",
    "\n",
    "def model_lem_fit_and_scores(model):\n",
    "    model.fit(X_train_lem,y_train)\n",
    "    print(f' Score on train data:  {model.score(X_train_lem,y_train)}')\n",
    "    print(f' Score on test data: {model.score(X_test_lem, y_test)}')\n",
    "    print(f' balanced accuracy score on train data: {balanced_accuracy_score(y_train, model.predict(X_train_lem))}')\n",
    "    print(f' balanced accuracy score on test data: {balanced_accuracy_score(y_test, model.predict(X_test_lem))}')\n",
    "    print(model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "def lemmatized(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    lemma_list = [token.lemma_ for token in doc]\n",
    "    lemma_sentence = ' '.join(lemma_list)\n",
    "    return lemma_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lem = X_train.apply(lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_lem = X_test.apply(lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = make_pipeline(CountVectorizer(),\n",
    "                     StandardScaler(with_mean=False),\n",
    "                     LogisticRegression(max_iter=10000))\n",
    "params2 = { \n",
    "          'countvectorizer__stop_words': [None, 'english'], \n",
    "          'countvectorizer__max_features':[3000,4000],\n",
    "          'countvectorizer__ngram_range':[(1,1), (1,2)],\n",
    "          'logisticregression__C':[.005, .01]\n",
    "}\n",
    "\n",
    "gs2 = GridSearchCV(pipe2, params2, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Score on train data:  0.9692982456140351\n",
      " Score on test data: 0.9048903878583474\n",
      " balanced accuracy score on train data: 0.9685591998482164\n",
      " balanced accuracy score on test data: 0.9037946196214408\n",
      "{'countvectorizer__max_features': 4000, 'countvectorizer__ngram_range': (1, 1), 'countvectorizer__stop_words': None, 'logisticregression__C': 0.005}\n"
     ]
    }
   ],
   "source": [
    "model_lem_fit_and_scores(gs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe3 = make_pipeline(CountVectorizer(),\n",
    "                     StandardScaler(with_mean=False),\n",
    "                     LogisticRegression(max_iter=10000))\n",
    "params3 = { \n",
    "          'countvectorizer__stop_words': [None, 'english'], \n",
    "          'countvectorizer__max_features':[4000,5000],\n",
    "          'countvectorizer__ngram_range':[(1,1), (1,2)],\n",
    "          'logisticregression__C':[.003, .005, .007]\n",
    "}\n",
    "\n",
    "gs3 = GridSearchCV(pipe3, params3, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Score on train data:  0.9728969860548808\n",
      " Score on test data: 0.9042158516020236\n",
      " balanced accuracy score on train data: 0.9720016776087623\n",
      " balanced accuracy score on test data: 0.9023586943604871\n",
      "{'countvectorizer__max_features': 5000, 'countvectorizer__ngram_range': (1, 1), 'countvectorizer__stop_words': None, 'logisticregression__C': 0.003}\n"
     ]
    }
   ],
   "source": [
    "model_lem_fit_and_scores(gs3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe4 = make_pipeline(CountVectorizer(),\n",
    "                     StandardScaler(with_mean=False),\n",
    "                     LogisticRegression(max_iter=10000))\n",
    "params4 = { \n",
    "          'countvectorizer__stop_words': [None, 'english'], \n",
    "          'countvectorizer__max_features':[4500,5000],\n",
    "          'countvectorizer__ngram_range':[(1,1)],\n",
    "          'logisticregression__C':[.001, .003]\n",
    "}\n",
    "\n",
    "gs4 = GridSearchCV(pipe4, params4, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Score on train data:  0.9691857849752586\n",
      " Score on test data: 0.9042158516020236\n",
      " balanced accuracy score on train data: 0.9681824291989956\n",
      " balanced accuracy score on test data: 0.9022833860107946\n",
      "{'countvectorizer__max_features': 4500, 'countvectorizer__ngram_range': (1, 1), 'countvectorizer__stop_words': None, 'logisticregression__C': 0.003}\n"
     ]
    }
   ],
   "source": [
    "model_lem_fit_and_scores(gs4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe10 = make_pipeline(CountVectorizer(),\n",
    "                     StandardScaler(with_mean=False),\n",
    "                     LogisticRegression(max_iter=10000))\n",
    "params10 = { \n",
    "          'countvectorizer__stop_words': [None, 'english'], \n",
    "          'countvectorizer__max_features':[4000,4500],\n",
    "          'countvectorizer__ngram_range':[(1,1)],\n",
    "          'logisticregression__C':[.004, .003, .005]\n",
    "}\n",
    "\n",
    "gs10 = GridSearchCV(pipe10, params10, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Score on train data:  0.9691857849752586\n",
      " Score on test data: 0.9042158516020236\n",
      " balanced accuracy score on train data: 0.9681824291989956\n",
      " balanced accuracy score on test data: 0.9022833860107946\n",
      "{'countvectorizer__max_features': 4500, 'countvectorizer__ngram_range': (1, 1), 'countvectorizer__stop_words': None, 'logisticregression__C': 0.003}\n"
     ]
    }
   ],
   "source": [
    "model_lem_fit_and_scores(gs10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since this is the best so far with lemmatized text, I will input this into my model summary\n",
    "\n",
    "input_to_df(gs10, 'deep', 'yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ^^ Best so far!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVectorizer didn't do better than CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe20 = make_pipeline(TfidfVectorizer(),\n",
    "                     StandardScaler(with_mean=False),\n",
    "                    LogisticRegression(max_iter=10000))\n",
    "params20 = { \n",
    "          'tfidfvectorizer__stop_words': [None, 'english'], \n",
    "          'tfidfvectorizer__max_features':[4000,5000],\n",
    "          'tfidfvectorizer__ngram_range':[(1,1),(1,2)],\n",
    "          'logisticregression__C':[.003, .005]\n",
    "}\n",
    "\n",
    "gs20 = GridSearchCV(pipe20, params20, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Score on train data:  0.9742465137201979\n",
      " Score on test data: 0.8984822934232715\n",
      " balanced accuracy score on train data: 0.9732425243095802\n",
      " balanced accuracy score on test data: 0.896592193541077\n",
      "{'logisticregression__C': 0.003, 'tfidfvectorizer__max_features': 5000, 'tfidfvectorizer__ngram_range': (1, 1), 'tfidfvectorizer__stop_words': 'english'}\n"
     ]
    }
   ],
   "source": [
    "model_lem_fit_and_scores(gs20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe21 = make_pipeline(TfidfVectorizer(),\n",
    "                     StandardScaler(with_mean=False),\n",
    "                    LogisticRegression(max_iter=10000))\n",
    "params21 = { \n",
    "          'tfidfvectorizer__stop_words': [None, 'english'], \n",
    "          'tfidfvectorizer__max_features':[5500,5200],\n",
    "          'tfidfvectorizer__ngram_range':[(1,1)],\n",
    "          'logisticregression__C':[.0005, .001, .003]\n",
    "}\n",
    "\n",
    "gs21 = GridSearchCV(pipe21, params21, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Score on train data:  0.9665991902834008\n",
      " Score on test data: 0.896795952782462\n",
      " balanced accuracy score on train data: 0.9648004037322186\n",
      " balanced accuracy score on test data: 0.8933412679623081\n",
      "{'logisticregression__C': 0.0005, 'tfidfvectorizer__max_features': 5500, 'tfidfvectorizer__ngram_range': (1, 1), 'tfidfvectorizer__stop_words': 'english'}\n"
     ]
    }
   ],
   "source": [
    "model_lem_fit_and_scores(gs21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will save this into summary to show tfidfvectorizer did slightly worse this time than countvectorizer\n",
    "\n",
    "input_to_df(gs20, 'deep', 'yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking highest and lowest correlated words..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = gs10.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = best.named_steps['logisticregression'].coef_\n",
    "vocab = best.named_steps['countvectorizer'].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame({'coefs': coefs[0], 'word': vocab})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefs</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.019826</td>\n",
       "      <td>ab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015700</td>\n",
       "      <td>abandon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.001103</td>\n",
       "      <td>abbey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003283</td>\n",
       "      <td>ability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005280</td>\n",
       "      <td>able</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      coefs     word\n",
       "0  0.019826       ab\n",
       "1  0.015700  abandon\n",
       "2 -0.001103    abbey\n",
       "3  0.003283  ability\n",
       "4  0.005280     able"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefs</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>0.445701</td>\n",
       "      <td>hike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4041</th>\n",
       "      <td>0.255881</td>\n",
       "      <td>trail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>0.223324</td>\n",
       "      <td>hiking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2485</th>\n",
       "      <td>0.185376</td>\n",
       "      <td>mountain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2806</th>\n",
       "      <td>0.183078</td>\n",
       "      <td>park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.155665</td>\n",
       "      <td>colorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>0.140908</td>\n",
       "      <td>lake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4163</th>\n",
       "      <td>0.134003</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4229</th>\n",
       "      <td>0.129965</td>\n",
       "      <td>view</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.129964</td>\n",
       "      <td>boot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         coefs      word\n",
       "1756  0.445701      hike\n",
       "4041  0.255881     trail\n",
       "1758  0.223324    hiking\n",
       "2485  0.185376  mountain\n",
       "2806  0.183078      park\n",
       "860   0.155665  colorado\n",
       "2072  0.140908      lake\n",
       "4163  0.134003       usa\n",
       "4229  0.129965      view\n",
       "501   0.129964      boot"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df.nlargest(10,'coefs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefs</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2941</th>\n",
       "      <td>-0.285682</td>\n",
       "      <td>plant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>-0.260657</td>\n",
       "      <td>garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>-0.181512</td>\n",
       "      <td>grow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>-0.157635</td>\n",
       "      <td>flower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2518</th>\n",
       "      <td>-0.144450</td>\n",
       "      <td>my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007</th>\n",
       "      <td>-0.143598</td>\n",
       "      <td>tomato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4093</th>\n",
       "      <td>-0.142555</td>\n",
       "      <td>tulip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>-0.123279</td>\n",
       "      <td>bloom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>-0.119880</td>\n",
       "      <td>gardening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4055</th>\n",
       "      <td>-0.118670</td>\n",
       "      <td>tree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         coefs       word\n",
       "2941 -0.285682      plant\n",
       "1530 -0.260657     garden\n",
       "1632 -0.181512       grow\n",
       "1445 -0.157635     flower\n",
       "2518 -0.144450         my\n",
       "4007 -0.143598     tomato\n",
       "4093 -0.142555      tulip\n",
       "465  -0.123279      bloom\n",
       "1533 -0.119880  gardening\n",
       "4055 -0.118670       tree"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df.nsmallest(10,'coefs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Checking that my lemmatization worked by comparing X_train and X_train_lem\n",
    "- I found out that spacy lemmatizes certain words like \"hiking\" based on what part of speech they are. For example, verbs were lemmatized from \"hiking\" to \"hike\" but if \"hiking\" was used as an adjective or a noun, they were not lemmatized. Hence, \"hiking\" was still present in some texts after lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'be you go hike gardening run'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#It does lemmatize \"hiking\" because it's a verb\n",
    "\n",
    "lemmatized('are you going hiking gardening running')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I can not bring my hiking gear tomorrow'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#It does not lemmatize \"hiking\" because it's an adjective\n",
    "lemmatized('i cannot bring my hiking gear tomorrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'help finding a good hiking backpack'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[3296]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'help find a good hiking backpack'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_lem[3296]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change in count below shows that hundreds of \"hiking\" were indeed lemmatized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "593"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([text for text in X_train if \"hiking\" in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([text for text in X_train_lem if \"hiking\" in text])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
