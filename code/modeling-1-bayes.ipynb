{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling - Naive Bayes (after minimal data cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import plot_confusion_matrix, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data\n",
    "\n",
    "postings = pd.read_csv('../datasets/postings_minimally_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hiking</td>\n",
       "      <td>Boulder Flatiron Loop Hike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hiking</td>\n",
       "      <td>Washington state lakes to swim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hiking</td>\n",
       "      <td>Here's a fun episode, demonstrating why a fly-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hiking</td>\n",
       "      <td>Picture I took of my friend at Angel’s Landing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hiking</td>\n",
       "      <td>Hiking to Bertha Peak via Cougar Crest Trail a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12448</th>\n",
       "      <td>gardening</td>\n",
       "      <td>Nope haha Oklahoma so not too far away.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12449</th>\n",
       "      <td>gardening</td>\n",
       "      <td>I'm transitioning to everbearing in strawberry...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12450</th>\n",
       "      <td>gardening</td>\n",
       "      <td>So pretty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12451</th>\n",
       "      <td>gardening</td>\n",
       "      <td>I think it’s 30% chance of frost after that date.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12452</th>\n",
       "      <td>gardening</td>\n",
       "      <td>My understanding is that the caterpillars eat ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12453 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           topic                                               text\n",
       "0         hiking                         Boulder Flatiron Loop Hike\n",
       "1         hiking                     Washington state lakes to swim\n",
       "2         hiking  Here's a fun episode, demonstrating why a fly-...\n",
       "3         hiking  Picture I took of my friend at Angel’s Landing...\n",
       "4         hiking  Hiking to Bertha Peak via Cougar Crest Trail a...\n",
       "...          ...                                                ...\n",
       "12448  gardening            Nope haha Oklahoma so not too far away.\n",
       "12449  gardening  I'm transitioning to everbearing in strawberry...\n",
       "12450  gardening                                          So pretty\n",
       "12451  gardening  I think it’s 30% chance of frost after that date.\n",
       "12452  gardening  My understanding is that the caterpillars eat ...\n",
       "\n",
       "[12453 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define X and y\n",
    "\n",
    "X = postings['text']\n",
    "y = np.where(postings['topic'] == 'hiking',1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                               Boulder Flatiron Loop Hike\n",
       "1                           Washington state lakes to swim\n",
       "2        Here's a fun episode, demonstrating why a fly-...\n",
       "3        Picture I took of my friend at Angel’s Landing...\n",
       "4        Hiking to Bertha Peak via Cougar Crest Trail a...\n",
       "                               ...                        \n",
       "12448              Nope haha Oklahoma so not too far away.\n",
       "12449    I'm transitioning to everbearing in strawberry...\n",
       "12450                                            So pretty\n",
       "12451    I think it’s 30% chance of frost after that date.\n",
       "12452    My understanding is that the caterpillars eat ...\n",
       "Name: text, Length: 12453, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking X\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking y\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6986"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y)  #this should be 6986 (number of hiking rows) -- confirmed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, test, split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, stratify=y, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_to_df(model, cleaning, lemmatized):\n",
    "    \"\"\"\n",
    "    Appends model information into model summary dataframe for comparison\n",
    "    \"\"\"\n",
    "    df = pd.read_csv('../datasets/model_list_summary.csv')\n",
    "    \n",
    "    if lemmatized == 'no':\n",
    "        info = [cleaning,          #Indicates if data was minimally or deeply cleaned\n",
    "                lemmatized,        #Indicates if text was lemmatized or not\n",
    "                model.score(X_train,y_train), \n",
    "                model.score(X_test, y_test), \n",
    "                balanced_accuracy_score(y_train, model.predict(X_train)),\n",
    "                balanced_accuracy_score(y_test, model.predict(X_test)),\n",
    "                model.best_params_\n",
    "               ]\n",
    "    elif lemmatized == 'yes': \n",
    "        info = [cleaning,          #Indicates if data was minimally or deeply cleaned\n",
    "                lemmatized,        #Indicates if text was lemmatized or not\n",
    "                model.score(X_train_lem,y_train), \n",
    "                model.score(X_test_lem, y_test), \n",
    "                balanced_accuracy_score(y_train, model.predict(X_train_lem)),\n",
    "                balanced_accuracy_score(y_test, model.predict(X_test_lem)),\n",
    "                model.best_params_\n",
    "               ]\n",
    "    info_series = pd.Series(info, index=df.columns)\n",
    "    df = df.append(info_series, ignore_index=True)\n",
    "    df.to_csv('../datasets/model_list_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building my pipe and GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit_and_scores(model):\n",
    "    model.fit(X_train,y_train)\n",
    "    print(f' Score on train data:  {model.score(X_train,y_train)}')\n",
    "    print(f' Score on test data: {model.score(X_test, y_test)}')\n",
    "    print(f' balanced accuracy score on train data: {balanced_accuracy_score(y_train, model.predict(X_train))}')\n",
    "    print(f' balanced accuracy score on test data: {balanced_accuracy_score(y_test, model.predict(X_test))}')\n",
    "    print(model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(CountVectorizer(),\n",
    "                     MultinomialNB())\n",
    "params = { \n",
    "        'countvectorizer__stop_words': [None, 'english'], \n",
    "        'countvectorizer__max_features':[500,4000,6000],\n",
    "        'countvectorizer__ngram_range':[(1,1), (2,2)],\n",
    "        'multinomialnb__alpha':[.005,.1, 1, 10]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Score on train data:  0.934468358496627\n",
      " Score on test data: 0.9165061014771998\n",
      " balanced accuracy score on train data: 0.9337440118436307\n",
      " balanced accuracy score on test data: 0.915641779470209\n",
      "{'countvectorizer__max_features': 6000, 'countvectorizer__ngram_range': (1, 1), 'countvectorizer__stop_words': 'english', 'multinomialnb__alpha': 0.1}\n"
     ]
    }
   ],
   "source": [
    "model_fit_and_scores(gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = make_pipeline(CountVectorizer(),\n",
    "                     MultinomialNB())\n",
    "params2 = { \n",
    "        'countvectorizer__stop_words': [None, 'english'], \n",
    "        'countvectorizer__max_features':[5500,6000,6500],\n",
    "        'countvectorizer__ngram_range':[(1,1), (1,2)],\n",
    "        'multinomialnb__alpha':[.05, .1, .5]\n",
    "}\n",
    "\n",
    "gs2 = GridSearchCV(pipe2, params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Score on train data:  0.9373594603276582\n",
      " Score on test data: 0.9171483622350675\n",
      " balanced accuracy score on train data: 0.9367980763411375\n",
      " balanced accuracy score on test data: 0.9162937488406293\n",
      "{'countvectorizer__max_features': 6500, 'countvectorizer__ngram_range': (1, 1), 'countvectorizer__stop_words': 'english', 'multinomialnb__alpha': 0.1}\n"
     ]
    }
   ],
   "source": [
    "model_fit_and_scores(gs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe3 = make_pipeline(CountVectorizer(),\n",
    "                     MultinomialNB())\n",
    "params3 = { \n",
    "        'countvectorizer__stop_words': ['english'], \n",
    "        'countvectorizer__max_features':[6500,6600,6700],\n",
    "        'countvectorizer__ngram_range':[(1,1)],\n",
    "        'multinomialnb__alpha':[.09, .1, .12]\n",
    "}\n",
    "\n",
    "gs3 = GridSearchCV(pipe3, params3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Score on train data:  0.9376806938644394\n",
      " Score on test data: 0.9171483622350675\n",
      " balanced accuracy score on train data: 0.9371639299996741\n",
      " balanced accuracy score on test data: 0.9163733083656003\n",
      "{'countvectorizer__max_features': 6700, 'countvectorizer__ngram_range': (1, 1), 'countvectorizer__stop_words': 'english', 'multinomialnb__alpha': 0.12}\n"
     ]
    }
   ],
   "source": [
    "model_fit_and_scores(gs3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe4 = make_pipeline(CountVectorizer(),\n",
    "                     MultinomialNB())\n",
    "params4 = { \n",
    "        'countvectorizer__stop_words': ['english'], \n",
    "        'countvectorizer__max_features':[6500,6700,7000],\n",
    "        'countvectorizer__ngram_range':[(1,1)],\n",
    "        'multinomialnb__alpha':[.12, .14, .15]\n",
    "}\n",
    "\n",
    "gs4 = GridSearchCV(pipe4, params4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Score on train data:  0.9376806938644394\n",
      " Score on test data: 0.9171483622350675\n",
      " balanced accuracy score on train data: 0.9371639299996741\n",
      " balanced accuracy score on test data: 0.9163733083656003\n",
      "{'countvectorizer__max_features': 6700, 'countvectorizer__ngram_range': (1, 1), 'countvectorizer__stop_words': 'english', 'multinomialnb__alpha': 0.12}\n"
     ]
    }
   ],
   "source": [
    "model_fit_and_scores(gs4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since this is the best so far, I will input this into my model summary\n",
    "\n",
    "input_to_df(gs4, 'minimal', 'no')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
